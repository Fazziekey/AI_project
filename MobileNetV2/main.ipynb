{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# MobileNetV2 — 垃圾分类\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 实验简介\n",
    "\n",
    "MindSpore是最佳匹配Ascend（昇腾）芯片的开源AI计算框架，同时也支持CPU、GPU平台。访问MindSpore官网了解更多：https://www.mindspore.cn/\n",
    "\n",
    "深度学习计算中，从头开始训练一个实用的模型通常非常耗时，需要大量计算能力。常用的数据如OpenImage、ImageNet、VOC、COCO等公开大型数据集，规模达到几十万甚至超过上百万张。网络和开源社区上通常会提供这些数据集上预训练好的模型。大部分细分领域任务在训练网络模型时，如果不使用预训练模型而从头开始训练网络，不仅耗时，且模型容易陷入局部极小值和过拟合。因此大部分任务都会选择预训练模型，在其上做微调（也称为Fine-Tune）。\n",
    "\n",
    "本实验以MobileNetV2+垃圾分类数据集为例，主要介绍如在使用MindSpore在CPU/GPU平台上进行Fine-Tune。\n",
    "\n",
    "垃圾分类信息：\n",
    "\n",
    "    {\n",
    "        '干垃圾': ['贝壳', '打火机', '旧镜子', '扫把', '陶瓷碗', '牙刷', '一次性筷子', '脏污衣服'],\n",
    "        '可回收物': ['报纸', '玻璃制品', '篮球', '塑料瓶', '硬纸板', '玻璃瓶', '金属制品', '帽子', '易拉罐', '纸张'],\n",
    "        '湿垃圾': ['菜叶', '橙皮', '蛋壳', '香蕉皮'],\n",
    "        '有害垃圾': ['电池', '药片胶囊', '荧光灯', '油漆桶']\n",
    "    }\n",
    "\n",
    "    ['贝壳', '打火机', '旧镜子', '扫把', '陶瓷碗', '牙刷', '一次性筷子', '脏污衣服',\n",
    "    '报纸', '玻璃制品', '篮球', '塑料瓶', '硬纸板', '玻璃瓶', '金属制品', '帽子', '易拉罐', '纸张',\n",
    "    '菜叶', '橙皮', '蛋壳', '香蕉皮',\n",
    "    '电池', '药片胶囊', '荧光灯', '油漆桶']\n",
    "    \n",
    "    ['Seashell', 'Lighter', 'Old Mirror', 'Broom', 'Ceramic Bowl', 'Toothbrush', 'Disposable Chopsticks', 'Dirty Cloth',\n",
    "    'Newspaper', 'Glassware', 'Basketball', 'Plastic Bottle', 'Cardboard', 'Glass Bottle', 'Metalware', 'Hats', 'Cans', 'Paper',\n",
    "    'Vegetable Leaf', 'Orange Peel', 'Eggshell', 'Banana Peel',\n",
    "    'Battery', 'Tablet capsules', 'Fluorescent lamp', 'Paint bucket']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "脚本、预训练模型的 Checkpoint 和数据集组织为如下形式：\n",
    "\n",
    "```bash\n",
    "├── main.ipynb # 入口Jupyter Notebook文件\n",
    "│\n",
    "├── src_mindspore\n",
    "│   ├── dataset.py\n",
    "│   ├── mobilenetv2.py\n",
    "│   └── mobilenetv2-200_1067_gpu_cpu.ckpt\n",
    "│\n",
    "├── results/mobilenetv2.mindir # 待生成的MindSpore0.5.0模型文件\n",
    "│\n",
    "├── train_main.py # 将 main.ipynb Notebook 训练模型代码转化为py文件\n",
    "│\n",
    "└── datasets/5fbdf571c06d3433df85ac65-momodel/garbage_26x100/ # 数据集\n",
    "    ├── train/\n",
    "    ├── val/\n",
    "    └── label.txt\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入标准库、第三方库，已及 MindSpore 的模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from easydict import EasyDict\n",
    "from PIL import Image\n",
    "\n",
    "import mindspore as ms\n",
    "from mindspore import context\n",
    "from mindspore import nn\n",
    "from mindspore import Tensor\n",
    "from mindspore.train.model import Model\n",
    "from mindspore.train.serialization import load_checkpoint, save_checkpoint, export\n",
    "from mindspore.train.callback import Callback, LossMonitor, ModelCheckpoint, CheckpointConfig\n",
    "\n",
    "from src_mindspore.dataset import create_dataset # 数据处理脚本\n",
    "from src_mindspore.mobilenetv2 import MobileNetV2Backbone, mobilenet_v2 # 模型定义脚本\n",
    "\n",
    "os.environ['GLOG_v'] = '2' # Log Level = Error\n",
    "has_gpu = (os.system('command -v nvidia-smi') == 0)\n",
    "print('Excuting with', 'GPU' if has_gpu else 'CPU', '.')\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target='GPU' if has_gpu else 'CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "配置后续训练、验证、推理用到的参数。可以调整以下超参以提高模型训练后的验证精度：\n",
    "\n",
    "- `epochs`：在训练集上训练的代数；\n",
    "- `lr_max`：学习率，或者动态学习率的最大值；\n",
    "- `decay_type`：学习率下降策略；\n",
    "- `momentum`：Momentum优化器的动量参数，通常为0.9；\n",
    "- `weight_decay`：正则化项的系数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 垃圾分类数据集标签，以及用于标签映射的字典。\n",
    "index = {'00_00': 0, '00_01': 1, '00_02': 2, '00_03': 3, '00_04': 4, '00_05': 5, '00_06': 6, '00_07': 7,\n",
    "         '00_08': 8, '00_09': 9, '01_00': 10, '01_01': 11, '01_02': 12, '01_03': 13, '01_04': 14, \n",
    "         '01_05': 15, '01_06': 16, '01_07': 17, '02_00': 18, '02_01': 19, '02_02': 20, '02_03': 21,\n",
    "         '03_00': 22, '03_01': 23, '03_02': 24, '03_03': 25}\n",
    "inverted = {0: 'Plastic Bottle', 1: 'Hats', 2: 'Newspaper', 3: 'Cans', 4: 'Glassware', 5: 'Glass Bottle', 6: 'Cardboard', 7: 'Basketball',\n",
    "            8: 'Paper', 9: 'Metalware', 10: 'Disposable Chopsticks', 11: 'Lighter', 12: 'Broom', 13: 'Old Mirror', 14: 'Toothbrush',\n",
    "            15: 'Dirty Cloth', 16: 'Seashell', 17: 'Ceramic Bowl', 18: 'Paint bucket', 19: 'Battery', 20: 'Fluorescent lamp', 21: 'Tablet capsules',\n",
    "            22: 'Orange Peel', 23: 'Vegetable Leaf', 24: 'Eggshell', 25: 'Banana Peel'}\n",
    "\n",
    "# 训练超参\n",
    "config = EasyDict({\n",
    "    \"num_classes\": 26, # 分类数，即输出层的维度\n",
    "    \"reduction\": 'mean', # mean, max, Head部分池化采用的方式\n",
    "    \"image_height\": 224,\n",
    "    \"image_width\": 224,\n",
    "    \"batch_size\": 24, # 鉴于CPU容器性能，太大可能会导致训练卡住\n",
    "    \"eval_batch_size\": 10,\n",
    "    \"epochs\": 4, # 请尝试修改以提升精度\n",
    "    \"lr_max\": 0.01, # 请尝试修改以提升精度\n",
    "    \"decay_type\": 'constant', # 请尝试修改以提升精度\n",
    "    \"momentum\": 0.8, # 请尝试修改以提升精度\n",
    "    \"weight_decay\": 3.0, # 请尝试修改以提升精度\n",
    "    \"dataset_path\": \"./datasets/5fbdf571c06d3433df85ac65-momodel/garbage_26x100\",\n",
    "    \"features_path\": \"./results/garbage_26x100_features\", # 临时目录，保存冻结层Feature Map，可随时删除\n",
    "    \"class_index\": index,\n",
    "    \"save_ckpt_epochs\": 1,\n",
    "    \"save_ckpt_path\": './results/ckpt_mobilenetv2',\n",
    "    \"pretrained_ckpt\": './src_mindspore/mobilenetv2-200_1067_cpu_gpu.ckpt',\n",
    "    \"export_path\": './results/mobilenetv2.mindir'\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "展示部分处理后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = create_dataset(config=config, training=False)\n",
    "data = ds.create_dict_iterator(output_numpy=True).get_next()\n",
    "images = data['image']\n",
    "labels = data['label']\n",
    "\n",
    "for i in range(1, 5):\n",
    "    plt.subplot(2, 2, i)\n",
    "    plt.imshow(np.transpose(images[i], (1,2,0)))\n",
    "    plt.title('label: %s' % inverted[labels[i]])\n",
    "    plt.xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 训练策略\n",
    "\n",
    "一般情况下，模型训练时采用静态学习率，如0.01。随着训练步数的增加，模型逐渐趋于收敛，对权重参数的更新幅度应该逐渐降低，以减小模型训练后期的抖动。所以，模型训练时可以采用动态下降的学习率，常见的学习率下降策略有：\n",
    "\n",
    "- polynomial decay/square decay;\n",
    "- cosine decay;\n",
    "- exponential decay;\n",
    "- stage decay.\n",
    "\n",
    "这里实现cosine decay和square decay下降策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lr(total_steps, lr_init=0.0, lr_end=0.0, lr_max=0.1, warmup_steps=0, decay_type='cosine'):\n",
    "    \"\"\"\n",
    "    Applies cosine decay to generate learning rate array.\n",
    "\n",
    "    Args:\n",
    "       total_steps(int): all steps in training.\n",
    "       lr_init(float): init learning rate.\n",
    "       lr_end(float): end learning rate\n",
    "       lr_max(float): max learning rate.\n",
    "       warmup_steps(int): all steps in warmup epochs.\n",
    "\n",
    "    Returns:\n",
    "       list, learning rate array.\n",
    "    \"\"\"\n",
    "    lr_init, lr_end, lr_max = float(lr_init), float(lr_end), float(lr_max)\n",
    "    decay_steps = total_steps - warmup_steps\n",
    "    lr_all_steps = []\n",
    "    inc_per_step = (lr_max - lr_init) / warmup_steps if warmup_steps else 0\n",
    "    for i in range(total_steps):\n",
    "        if i < warmup_steps:\n",
    "            lr = lr_init + inc_per_step * (i + 1)\n",
    "        else:\n",
    "            if decay_type == 'cosine':\n",
    "                cosine_decay = 0.5 * (1 + math.cos(math.pi * (i - warmup_steps) / decay_steps))\n",
    "                lr = (lr_max - lr_end) * cosine_decay + lr_end\n",
    "            elif decay_type == 'square':\n",
    "                frac = 1.0 - float(i - warmup_steps) / (total_steps - warmup_steps)\n",
    "                lr = (lr_max - lr_end) * (frac * frac) + lr_end\n",
    "            else:\n",
    "                lr = lr_max\n",
    "        lr_all_steps.append(lr)\n",
    "\n",
    "    return lr_all_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观察不同学习率下降策略的曲线："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 5*93\n",
    "plt.plot(range(steps), build_lr(steps, lr_max=0.1, decay_type='constant'))\n",
    "plt.plot(range(steps), build_lr(steps, lr_max=0.1, decay_type='square'))\n",
    "plt.plot(range(steps), build_lr(steps, lr_max=0.1, decay_type='cosine'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 模型训练\n",
    "\n",
    "在模型训练过程中，可以添加检查点（Checkpoint）用于保存模型的参数，以便进行推理及中断后再训练使用。使用场景如下：\n",
    "\n",
    "- 训练后推理场景\n",
    "    - 模型训练完毕后保存模型的参数，用于推理或预测操作。\n",
    "    - 训练过程中，通过实时验证精度，把精度最高的模型参数保存下来，用于预测操作。\n",
    "- 再训练场景\n",
    "    - 进行长时间训练任务时，保存训练过程中的Checkpoint文件，防止任务异常退出后从初始状态开始训练。\n",
    "    - Fine-tuning（微调）场景，即训练一个模型并保存参数，基于该模型，面向第二个类似任务进行模型训练。\n",
    "\n",
    "这里加载ImageNet数据上预训练的MobileNetv2进行Fine-tuning，并在训练过程中保存Checkpoint。训练有两种方式：\n",
    "- 方式一：冻结网络的Backbone，只训练修改的FC层（Head）。其中，Backbone再全量数据集上做一遍推理，得到Feature Map，将Feature Map作为训练Head的数据集，可以极大节省训练时间。\n",
    "- 方式二：先冻结网络的Backbone，只训练网络Head；再对Backbone+Head做整网做微调。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 提取特征集\n",
    "\n",
    "将冻结层在全量训练集上做一遍推理，然后保存FeatureMap，作为修改层的数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(net, dataset_path, config):\n",
    "    if not os.path.exists(config.features_path):\n",
    "        os.makedirs(config.features_path)\n",
    "    dataset = create_dataset(config=config)\n",
    "    step_size = dataset.get_dataset_size()\n",
    "    if step_size == 0:\n",
    "        raise ValueError(\"The step_size of dataset is zero. Check if the images count of train dataset is more \\\n",
    "            than batch_size in config.py\")\n",
    "\n",
    "    data_iter = dataset.create_dict_iterator()\n",
    "    for i, data in enumerate(data_iter):\n",
    "        features_path = os.path.join(config.features_path, f\"feature_{i}.npy\")\n",
    "        label_path = os.path.join(config.features_path, f\"label_{i}.npy\")\n",
    "        if not os.path.exists(features_path) or not os.path.exists(label_path):\n",
    "            image = data[\"image\"]\n",
    "            label = data[\"label\"]\n",
    "            features = net(image)\n",
    "            np.save(features_path, features.asnumpy())\n",
    "            np.save(label_path, label.asnumpy())\n",
    "        print(f\"Complete the batch {i+1}/{step_size}\")\n",
    "    return\n",
    "\n",
    "backbone = MobileNetV2Backbone()\n",
    "load_checkpoint(config.pretrained_ckpt, net=backbone)\n",
    "extract_features(backbone, config.dataset_path, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 训练 Head 层\n",
    "\n",
    "自定义Head层，CPU/GPU上算子支持情况请参考：https://www.mindspore.cn/doc/note/zh-CN/r1.0/operator_list_ms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalPooling(nn.Cell):\n",
    "    \"\"\"\n",
    "    Global avg pooling definition.\n",
    "\n",
    "    Args:\n",
    "        reduction: mean or max, which means AvgPooling or MaxpPooling.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "\n",
    "    Examples:\n",
    "        >>> GlobalAvgPooling()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super(GlobalPooling, self).__init__()\n",
    "        if reduction == 'max':\n",
    "            self.mean = ms.ops.ReduceMax(keep_dims=False)\n",
    "        else:\n",
    "            self.mean = ms.ops.ReduceMean(keep_dims=False)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.mean(x, (2, 3))\n",
    "        return x\n",
    "\n",
    "\n",
    "class MobileNetV2Head(nn.Cell):\n",
    "    \"\"\"\n",
    "    MobileNetV2Head architecture.\n",
    "\n",
    "    Args:\n",
    "        input_channel (int): Number of channels of input.\n",
    "        hw (int): Height and width of input, 7 for MobileNetV2Backbone with image(224, 224).\n",
    "        num_classes (int): Number of classes. Default is 1000.\n",
    "        reduction: mean or max, which means AvgPooling or MaxpPooling.\n",
    "        activation: Activation function for output logits.\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "\n",
    "    Examples:\n",
    "        >>> MobileNetV2Head(num_classes=1000)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_channel=1280, hw=7, num_classes=1000, reduction='mean', activation=\"None\"):\n",
    "        super(MobileNetV2Head, self).__init__()\n",
    "        if reduction:\n",
    "            self.flatten = GlobalPooling(reduction)\n",
    "        else:\n",
    "            self.flatten = nn.Flatten()\n",
    "            input_channel = input_channel * hw * hw\n",
    "        self.dense = nn.Dense(input_channel, num_classes, weight_init='ones', has_bias=False)\n",
    "        if activation == \"Sigmoid\":\n",
    "            self.activation = nn.Sigmoid()\n",
    "        elif activation == \"Softmax\":\n",
    "            self.activation = nn.Softmax()\n",
    "        else:\n",
    "            self.need_activation = False\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        if self.need_activation:\n",
    "            x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在提取的特征集上训练Head层，即修改层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_head():\n",
    "    train_dataset = create_dataset(config=config)\n",
    "    eval_dataset = create_dataset(config=config)\n",
    "    step_size = train_dataset.get_dataset_size()\n",
    "    \n",
    "    backbone = MobileNetV2Backbone()\n",
    "    # Freeze parameters of backbone. You can comment these two lines.\n",
    "    for param in backbone.get_parameters():\n",
    "       param.requires_grad = False\n",
    "    load_checkpoint(config.pretrained_ckpt, net=backbone)\n",
    "\n",
    "    head = MobileNetV2Head(input_channel=backbone.out_channels, num_classes=config.num_classes, reduction=config.reduction)\n",
    "    network = mobilenet_v2(backbone, head)\n",
    "\n",
    "    loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "    lrs = build_lr(config.epochs * step_size, lr_max=config.lr_max, warmup_steps=0, decay_type=config.decay_type)\n",
    "    opt = nn.Momentum(head.trainable_params(), lrs, config.momentum, config.weight_decay)\n",
    "    net = nn.WithLossCell(head, loss)\n",
    "    train_step = nn.TrainOneStepCell(net, opt)\n",
    "    train_step.set_train()\n",
    "    \n",
    "    # train\n",
    "    history = list()\n",
    "    features_path = config.features_path\n",
    "    idx_list = list(range(step_size))\n",
    "    for epoch in range(config.epochs):\n",
    "        random.shuffle(idx_list)\n",
    "        epoch_start = time.time()\n",
    "        losses = []\n",
    "        for j in idx_list:\n",
    "            feature = Tensor(np.load(os.path.join(features_path, f\"feature_{j}.npy\")))\n",
    "            label = Tensor(np.load(os.path.join(features_path, f\"label_{j}.npy\")))\n",
    "            losses.append(train_step(feature, label).asnumpy())\n",
    "        epoch_seconds = (time.time() - epoch_start)\n",
    "        epoch_loss = np.mean(np.array(losses))\n",
    "        \n",
    "        history.append(epoch_loss)\n",
    "        print(\"epoch: {}, time cost: {}, avg loss: {}\".format(epoch + 1, epoch_seconds, epoch_loss))\n",
    "        if (epoch + 1) % config.save_ckpt_epochs == 0:\n",
    "            save_checkpoint(network, os.path.join(config.save_ckpt_path, f\"mobilenetv2-{epoch+1}.ckpt\"))\n",
    "    \n",
    "    # evaluate\n",
    "    print('validating the model...')\n",
    "    eval_model = Model(network, loss, metrics={'acc', 'loss'})\n",
    "    acc = eval_model.eval(eval_dataset, dataset_sink_mode=False)\n",
    "    print(acc)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于MobileNetV2网络较大，验证（validate）模型时执行的是整网，整网在CPU平台上执行较慢，如遇卡住或者验证过程中Notebook中断，请重启Kernel后重新执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(config.save_ckpt_path):\n",
    "    shutil.rmtree(config.save_ckpt_path)\n",
    "os.makedirs(config.save_ckpt_path)\n",
    "\n",
    "history = train_head()\n",
    "\n",
    "plt.plot(history, label='train_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "CKPT = f'mobilenetv2-{config.epochs}.ckpt'\n",
    "print(\"Chosen checkpoint is\", CKPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型推理\n",
    "\n",
    "加载模型Checkpoint进行推理。\n",
    "\n",
    "> 使用load_checkpoint接口加载数据时，需要把数据传入给原始网络，而不能传递给带有优化器和损失函数的训练网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_process(image):\n",
    "    \"\"\"Precess one image per time.\n",
    "    \n",
    "    Args:\n",
    "        image: shape (H, W, C)\n",
    "    \"\"\"\n",
    "    mean=[0.485*255, 0.456*255, 0.406*255]\n",
    "    std=[0.229*255, 0.224*255, 0.225*255]\n",
    "    image = (np.array(image) - mean) / std\n",
    "    image = image.transpose((2,0,1))\n",
    "    img_tensor = Tensor(np.array([image], np.float32))\n",
    "    return img_tensor\n",
    "\n",
    "def infer_one(network, image_path):\n",
    "    image = Image.open(image_path).resize((config.image_height, config.image_width))\n",
    "    logits = network(image_process(image))\n",
    "    pred = np.argmax(logits.asnumpy(), axis=1)[0]\n",
    "    print(image_path, inverted[pred])\n",
    "    return pred\n",
    "\n",
    "def infer(images):\n",
    "    backbone = MobileNetV2Backbone()\n",
    "    head = MobileNetV2Head(input_channel=backbone.out_channels, num_classes=config.num_classes, reduction=config.reduction)\n",
    "    network = mobilenet_v2(backbone, head)\n",
    "    print('加载模型路径:',os.path.join(config.save_ckpt_path, CKPT))\n",
    "    load_checkpoint(os.path.join(config.save_ckpt_path, CKPT), net=network)\n",
    "    for img in images:\n",
    "        infer_one(network, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = list()\n",
    "folder = os.path.join(config.dataset_path, 'val/00_01') # Hats\n",
    "for img in os.listdir(folder):\n",
    "    test_images.append(os.path.join(folder, img))\n",
    "\n",
    "infer(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 导出 MindIR 模型文件\n",
    "\n",
    "当有了 CheckPoint 文件后，如果想继续基于 MindSpore Lite 在手机端做推理，需要通过网络和 Checkpoint 生成对应的 MindIR 格式模型文件。当前支持基于静态图，且不包含控制流语义的推理网络导出。导出该格式文件的代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = MobileNetV2Backbone()\n",
    "# 导出带有Softmax层的模型\n",
    "head = MobileNetV2Head(input_channel=backbone.out_channels, num_classes=config.num_classes,\n",
    "                       reduction=config.reduction, activation='Softmax')\n",
    "network = mobilenet_v2(backbone, head)\n",
    "load_checkpoint(os.path.join(config.save_ckpt_path, CKPT), net=network)\n",
    "\n",
    "input = np.random.uniform(0.0, 1.0, size=[1, 3, 224, 224]).astype(np.float32)\n",
    "export(network, Tensor(input), file_name=config.export_path, file_format='MINDIR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 在手机上部署模型（附加题）\n",
    "\n",
    "MindSpore提供了面想手机及IoT设备的高性能、轻量化端侧推理框架。访问MindSpore Lite官网了解更多：https://www.mindspore.cn/lite/\n",
    "\n",
    "通过本实验可以了解如何在端侧利用MindSpore Lite C++ API（Android JNI）以及MindSpore Lite图像分类模型完成端侧推理，实现对设备摄像头捕获的内容进行分类，并在App图像预览界面中显示出最可能的分类结果。\n",
    "\n",
    "实验教程和代码示例请下载：[mobilenetv2_android.zip](https://share-course.obs.cn-north-4.myhuaweicloud.com/materials/mobilenetv2_android.zip)。另外，也可以参考MindSpore官网教程[实现一个图像分类应用](https://www.mindspore.cn/tutorial/lite/zh-CN/r1.0/quick_start/quick_start.html)。\n",
    "\n",
    "> **注意：** 当前示例代码仅支持Android手机，无Android手机的同学可尝试通过AndroidStudio自带的模拟器体验。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 作业评分\n",
    "\n",
    "**注意：**\n",
    "\n",
    "通过对以上步骤流程的了解，相信大家对深度学习有了深刻的认识，但是模型比较简单，准确率也不高，大家可以试着写自己的深度学习模型，并将其调到最佳状态。          \n",
    "1. 你可以在我们准好的接口中实现深度学习模型（若使用可以修改函数接口），也可以自己实现深度学习模型，写好代码后可以在 Py 文件中使用 GPU 进行模型训练。\n",
    "2. 在训练模型等过程中如果需要**保存数据、模型**等请写到 **results** 文件夹，如果采用 [离线任务](https://momodel.cn/docs/#/zh-cn/%E5%9C%A8GPU%E6%88%96CPU%E8%B5%84%E6%BA%90%E4%B8%8A%E8%AE%AD%E7%BB%83%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B) 请务必将模型保存在 **results** 文件夹下。\n",
    "3. 训练出自己最好的模型后，先按照下列 cell 操作方式实现 NoteBook 加载模型测试；请测试通过在进行【系统测试】。\n",
    "4. 点击左侧栏`提交作业`后点击`生成文件`则只需勾选 `predict()` 函数的cell，即【**模型预测代码答题区域**】的 cell。\n",
    "5. 请导入必要的包和第三方库 (包括此文件中曾经导入过的)。\n",
    "6. 请加载你认为训练最佳的模型，即请按要求填写模型路径。\n",
    "7. `predict()`函数的输入和输出请不要改动。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===========================================  **模型预测代码答题区域**  ===========================================  \n",
    "在下方的代码块中编写 **模型预测** 部分的代码，请勿在别的位置作答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 生成 main.py 时请勾选此 cell\n",
    "# 本示范以 NoteBook 训练模型通过平台测试为例：\n",
    "\n",
    "# 1. 导入相关包\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mindspore as ms\n",
    "from mindspore import nn\n",
    "from mindspore import Tensor\n",
    "from easydict import EasyDict\n",
    "from mindspore import context\n",
    "from mindspore.train.serialization import load_checkpoint\n",
    "from src_mindspore.mobilenetv2 import MobileNetV2Backbone, mobilenet_v2  # 模型定义脚本\n",
    "\n",
    "os.environ['GLOG_v'] = '2'  # Log Level = Error\n",
    "has_gpu = (os.system('command -v nvidia-smi') == 0)\n",
    "print('Excuting with', 'GPU' if has_gpu else 'CPU', '.')\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target='GPU' if has_gpu else 'CPU')\n",
    "\n",
    "# 2.系统测试部分标签与该处一致，请不要改动\n",
    "# 垃圾分类数据集标签，以及用于标签映射的字典。\n",
    "index = {'00_00': 0, '00_01': 1, '00_02': 2, '00_03': 3, '00_04': 4, '00_05': 5, '00_06': 6, '00_07': 7,\n",
    "         '00_08': 8, '00_09': 9, '01_00': 10, '01_01': 11, '01_02': 12, '01_03': 13, '01_04': 14,\n",
    "         '01_05': 15, '01_06': 16, '01_07': 17, '02_00': 18, '02_01': 19, '02_02': 20, '02_03': 21,\n",
    "         '03_00': 22, '03_01': 23, '03_02': 24, '03_03': 25}\n",
    "inverted = {0: 'Plastic Bottle', 1: 'Hats', 2: 'Newspaper', 3: 'Cans', 4: 'Glassware', 5: 'Glass Bottle', 6: 'Cardboard', 7: 'Basketball',\n",
    "            8: 'Paper', 9: 'Metalware', 10: 'Disposable Chopsticks', 11: 'Lighter', 12: 'Broom', 13: 'Old Mirror', 14: 'Toothbrush',\n",
    "            15: 'Dirty Cloth', 16: 'Seashell', 17: 'Ceramic Bowl', 18: 'Paint bucket', 19: 'Battery', 20: 'Fluorescent lamp', 21: 'Tablet capsules',\n",
    "            22: 'Orange Peel', 23: 'Vegetable Leaf', 24: 'Eggshell', 25: 'Banana Peel'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 生成 main.py 时请勾选此 cell\n",
    "\n",
    "# 3. NoteBook 模型调整参数部分，你可以根据自己模型需求修改、增加、删除、完善部分超参数\n",
    "# 训练超参\n",
    "config = EasyDict({\n",
    "    \"num_classes\": 26,\n",
    "    \"reduction\": 'mean',\n",
    "    \"image_height\": 224,\n",
    "    \"image_width\": 224,\n",
    "    \"eval_batch_size\": 10\n",
    "})\n",
    "\n",
    "# 4. 自定义模型Head部分\n",
    "class GlobalPooling(nn.Cell):\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super(GlobalPooling, self).__init__()\n",
    "        if reduction == 'max':\n",
    "            self.mean = ms.ops.ReduceMax(keep_dims=False)\n",
    "        else:\n",
    "            self.mean = ms.ops.ReduceMean(keep_dims=False)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.mean(x, (2, 3))\n",
    "        return x\n",
    "\n",
    "\n",
    "class MobileNetV2Head(nn.Cell):\n",
    "    def __init__(self, input_channel=1280, hw=7, num_classes=1000, reduction='mean', activation=\"None\"):\n",
    "        super(MobileNetV2Head, self).__init__()\n",
    "        if reduction:\n",
    "            self.flatten = GlobalPooling(reduction)\n",
    "        else:\n",
    "            self.flatten = nn.Flatten()\n",
    "            input_channel = input_channel * hw * hw\n",
    "        self.dense = nn.Dense(input_channel, num_classes, weight_init='ones', has_bias=False)\n",
    "        if activation == \"Sigmoid\":\n",
    "            self.activation = nn.Sigmoid()\n",
    "        elif activation == \"Softmax\":\n",
    "            self.activation = nn.Softmax()\n",
    "        else:\n",
    "            self.need_activation = False\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        if self.need_activation:\n",
    "            x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# -------------------------- 5.请加载您最满意的模型 ---------------------------\n",
    "# 首先加载网络模型\n",
    "backbone = MobileNetV2Backbone()\n",
    "head = MobileNetV2Head(input_channel=backbone.out_channels, num_classes=config.num_classes, reduction=config.reduction)\n",
    "network = mobilenet_v2(backbone, head)\n",
    "\n",
    "# 加载模型,加载请注意 model_path 是相对路径, 与当前文件同级。\n",
    "# 如果你的模型是在 results 文件夹下的模型，则 model_path = './results/ckpt_mobilenetv2/mobilenetv2-4.ckpt'\n",
    "\n",
    "model_path = './results/ckpt_mobilenetv2/mobilenetv2-4.ckpt'\n",
    "load_checkpoint(model_path, net=network)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def image_process(image):\n",
    "    \"\"\"Precess one image per time.\n",
    "    \n",
    "    Args:\n",
    "        image: shape (H, W, C)\n",
    "    \"\"\"\n",
    "    mean=[0.485*255, 0.456*255, 0.406*255]\n",
    "    std=[0.229*255, 0.224*255, 0.225*255]\n",
    "    image = (np.array(image) - mean) / std\n",
    "    image = image.transpose((2,0,1))\n",
    "    img_tensor = Tensor(np.array([image], np.float32))\n",
    "    return img_tensor\n",
    "\n",
    "def predict(image):\n",
    "    \"\"\"\n",
    "    加载模型和模型预测\n",
    "    主要步骤:\n",
    "        1.图片处理,此处尽量与训练模型数据处理一致\n",
    "        2.用加载的模型预测图片的类别\n",
    "    :param image: OpenCV 读取的图片对象，数据类型是 np.array，shape (H, W, C)\n",
    "    :return: string, 模型识别图片的类别, \n",
    "            包含 'Plastic Bottle','Hats','Newspaper','Cans'等共 26 个类别\n",
    "    \"\"\"\n",
    "    # -------------------------- 实现图像处理部分的代码 ---------------------------\n",
    "    # 该处是与 NoteBook 训练数据预处理一致；\n",
    "    # 如使用其它方式进行数据处理，请修改完善该处，否则影响成绩\n",
    "    image = cv2.resize(image,(config.image_height, config.image_width))\n",
    "    image = image_process(image)\n",
    "    \n",
    "    # -------------------------- 实现模型预测部分的代码 ---------------------------\n",
    "    logits = network(image)\n",
    "    pred = np.argmax(logits.asnumpy(), axis=1)[0]\n",
    "    \n",
    "    return inverted[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入图片路径和名称\n",
    "image_path = './datasets/5fbdf571c06d3433df85ac65-momodel/garbage_26x100/val/00_00/00037.jpg'\n",
    "\n",
    "# 使用 opencv 读取图片\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# 打印返回结果\n",
    "print(predict(image))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
